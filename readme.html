<!doctype html>
<html lang="vi">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>README — Suggest Keywords</title>
  <link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <!-- Bootstrap (optional styling parity with test page) -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.3/dist/css/bootstrap.min.css" integrity="sha384-QWTKZyjpPEjISv5WaRU9OFeRpok6YctnYmDr5pNlyT2bRjXh0JMhjY6hW+ALEwIH" crossorigin="anonymous">
  <!-- Highlight.js theme -->
  <link id="hljs-theme" rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@11.9.0/styles/github.min.css">
  <style>
    :root{
      --ice-cold:#a0d2eb;--freeze-purple:#e5eaf5;--medium-purple:#d0bdf4;--purple-pain:#8458B3;--heavy-purple:#a28089;
      --bg:var(--freeze-purple);--panel:#fff;--muted:#6b6d83;--text:#22223b;--border:#dcdff0;--accent:var(--purple-pain);--accent-2:var(--medium-purple);
      --shadow:0 8px 24px rgba(0,0,0,.12);
    }
    body{margin:0;background:var(--bg);color:var(--text);font-family: system-ui, -apple-system, Segoe UI, Roboto, Ubuntu, Cantarell, Noto Sans, "Helvetica Neue", Arial, "Apple Color Emoji", "Segoe UI Emoji";}
    .wrap{max-width: 980px;margin: 28px auto;padding: 0 16px;}
    .doc{background:var(--panel);border:1px solid var(--border);border-radius:14px;box-shadow:var(--shadow);padding:28px;}
  .doc h1,.doc h2,.doc h3{line-height:1.25; scroll-margin-top: 90px;}
    .doc h1{font-size:28px;margin:0 0 12px}
    .doc h2{font-size:22px;margin:26px 0 10px;color:var(--purple-pain)}
    .doc h3{font-size:18px;margin:18px 0 8px}
    .doc p{line-height:1.7;color:#2b3042}
    .doc ul,.doc ol{padding-left:22px}
    .doc code{background:var(--freeze-purple);border:1px solid var(--border);border-radius:6px;padding:0 6px}
    .doc pre{background:#0f172a;color:#e2e8f0;border-radius:10px;padding:12px 14px;overflow:auto;border:1px solid #0b1226}
    .doc pre code{background:transparent;border:none;padding:0}
    .topbar{display:flex;justify-content:space-between;align-items:center;margin-bottom:12px}
    .btn{display:inline-flex;align-items:center;gap:6px;padding:8px 12px;border-radius:10px;border:1px solid var(--border);background:#fff;color:var(--text);text-decoration:none}
    .btn:hover{background:#f3f4f6}
    .muted{color:var(--muted)}
    .toc{background:#fafbff;border:1px solid var(--border);border-radius:12px;padding:16px;margin:18px 0;box-shadow:0 2px 4px rgba(0,0,0,.04)}
    .toc strong{color:#374151;display:block;margin-bottom:6px;font-size:14px;letter-spacing:.5px;text-transform:uppercase}
    .toc a{text-decoration:none;color:var(--purple-pain);font-size:14px;line-height:1.4;display:block;padding:4px 6px;border-radius:6px}
    .toc a:hover{background:rgba(132,88,179,.08)}
    .doc blockquote{margin:14px 0;padding:10px 14px;border-left:4px solid var(--purple-pain);background:linear-gradient(90deg,var(--freeze-purple),#fff)}
    .doc hr{border:none;border-top:1px solid var(--border);margin:32px 0}
    .doc table{width:100%;border-collapse:collapse;margin:16px 0;font-size:14px}
    .doc th,.doc td{border:1px solid var(--border);padding:8px 10px;text-align:left;vertical-align:top}
    .doc th{background:#f4f5fb;font-weight:600}
    .doc tr:nth-child(even){background:#fafbff}
    .anchor-link{opacity:0;margin-left:6px;font-size:.7em;transition:opacity .2s}
    .doc h1:hover .anchor-link,.doc h2:hover .anchor-link,.doc h3:hover .anchor-link,.doc h4:hover .anchor-link{opacity:1}
    @media (min-width:1100px){
      body.with-toc .wrap{display:grid;grid-template-columns:240px 1fr;gap:28px;align-items:start}
      body.with-toc .toc{position:sticky;top:18px;max-height:calc(100vh - 36px);overflow:auto}
    }
    /* Fallback if highlight CSS fails */
    .doc pre code .hljs-keyword{color:#c792ea}
    .doc pre code .hljs-string{color:#a5e844}
    .doc pre code .hljs-number{color:#ffcb6b}
    .doc pre code .hljs-comment{color:#546e7a}
  </style>
</head>
<body>
  <div class="wrap">
    <div class="topbar d-print-none">
      <div class="d-flex gap-2 flex-wrap">
        <a href="./index.html" class="btn">← Quay lại trang test</a>
  <a id="downloadMd" href="./README-suggest.md" class="btn" download>Tải README (.md)</a>
        <button id="toggleLayout" class="btn" type="button">Bật/Tắt side TOC</button>
        <button id="printBtn" class="btn" type="button" title="In hoặc lưu PDF">In / PDF</button>
      </div>
      <small class="muted">README tự render • <span id="renderStatus">loading…</span></small>
    </div>
    <nav id="tocRoot" class="toc d-print-none" style="display:none"></nav>
    <div class="doc" id="doc" data-loaded="false">
      <div class="muted">Đang tải README…</div>
    </div>
  </div>

  <!-- Inline fallback if fetch fails (e.g., opened via file://) -->
  <script type="text/markdown" id="readme-inline">
# Suggest Keywords System (Autocomplete)

This document describes the design and implementation of the suggest keywords feature exposed via `GET /api/search/suggest_keywords`, along with related maintenance endpoints and data pipelines.

## Overview

The endpoint provides smart autocomplete suggestions by combining multiple sources:

- Prefix matches on the current token
- Semantic neighbors from co-occurrence (PPMI) vectors
- Next-token predictions (1 and 2-step contexts) and on-the-fly multi-token phrase expansion
- Admin-curated phrases (custom phrases)
- Embedding-based neighbors (optional)

Performance:
- Parallel fetching for key branches (prefix vs neighbor, phrase_dict vs next)
- 20s Redis cache keyed by normalized query + trailing-space flag
- Response includes `x-suggest-latency-ms` header

Online learning:
- Query and suggestion clicks can be used to learn online (optional service hooks included).

## API: GET /api/search/suggest_keywords

- Auth: protected by auth middleware
- Query params
  - `query`: string (required)
- Response shape
  ```jsonc
  {
    "success": true,
    "message": "Thành công",
    "data": [
      {
        "text": "tai nghe bluetooth",     // Display form (keeps diacritics)
        "token": "tai nghe bluetooth",    // Normalized token(s)
        "type": "phrase",                 // custom | phrase_dict | phrase | next | prefix | neighbor | embedding
        "score": 0.42,                     // raw score before normalization/weight
        "full": "tai nghe bluetooth"      // Full query after applying suggestion
      }
    ]
  }
  ```
- Headers
  - `x-suggest-latency-ms`: processing time in ms
  - `x-cache`: "hit" when served from Redis cache

## Algorithm

1) Validate query (zod schema). If invalid → 400.

2) Normalize & tokenize
- `normalizePreserveDiacritics` keeps display diacritics but normalizes spacing/case.
- `SegmentService.tokens` produces normalized tokens for logic.
- `endsWithSpace` determines whether the last token is complete.
- Derive `lastToken`, `prevToken`, `prevPrevToken` accordingly.

3) Cache check
- Cache key: `suggest:<normalized_query>:space=<0|1>`.
- If query effectively empty → return empty list and cache for 20s.
- If cached result exists → return it (with `x-cache: hit`).

4) Utilities
- `displayOf(token)` via `keywordVectorRepo.displayMapForTokens` → display form with diacritics.
- `makeFullForPrefix` and `makeFullForNeighbor/Next/Phrase` compose the final full query string.

5) Candidates from multiple sources (parallelized when possible)

- Prefix (ENABLE_PREFIX, `lastToken` exists)
  - `keywordVectorRepo.suggestByPrefix(lastToken, LIMITS.PREFIX)`
  - → `{ text=display||token, token, type='prefix', score=freq, full=makeFullForPrefix(text) }`

- Neighbor (ENABLE_NEIGHBOR, `prevToken` exists, and not disabled on space)
  - `keywordVectorRepo.getByToken(prevToken)` → top `LIMITS.NEIGHBOR` neighbors (PPMI)
  - → `{ text=displayOf(n.token), token=n.token, type='neighbor', score=n.score, full=append }`

- Custom phrases (admin-curated)
  - `customPhraseRepo.findMatches(typedTokens, partial, 10)`
  - Take the tail (suffix beyond the already typed tokens) if any
  - → `{ type='custom', text=display||full, token=tailTokens.join(" "), score=priority||1, full=(append/replace) }`

- When `endsWithSpace` = true (a token just completed)
  - Phrase dictionary (ENABLE_PHRASE_DICT)
    - If `prevPrevToken` exists: `keywordPhraseRepo.getByPrefix2(prevPrev, prev, LIMITS.PHRASE_DICT)`
    - Else: `getByPrefix1(prev, LIMITS.PHRASE_DICT)`
    - Tail beyond the prefix → `{ type='phrase_dict', text=tailDisp, token=tailTokens.join(" "), score=pmi, full=rawQuery + tailDisp }`
  - Next token (ENABLE_NEXT)
    - Context priority: `prevPrev|||prev`, fallback `prev`
    - → `{ type='next', text=displayOf(token), token, score=count|score, full=append }`
    - Phrase expansion (ENABLE_PHRASE):
      - Seed from top `PHRASE_FIRST_LIMIT` next tokens; expand up to `MAX_PHRASE_TOKENS` with breadth `PHRASE_SECOND_LIMIT` using 2-step contexts where possible
      - Score phrase = product of (score|count) along the path
      - → `{ type='phrase', text=join displayOf(tokens), token=join tokens, score, full=append }`

- When not `endsWithSpace` and prefix docs exist
  - For the top 1–2 prefix completions, find 1–2 next tokens to form a 2-token phrase immediately
  - → items type `phrase` using `makeFullForPrefix`

- When not `endsWithSpace` and no prefix docs
  - Use `lastToken` to find next tokens and form 2-token phrases

- Embedding neighbors (optional, `EMBEDDINGS.ENABLED`)
  - `embeddingNeighborService.neighborsForQuery(query, K)`
  - → `{ type='embedding', text=displayOf(token), token, score, full=append }`

6) Fast path (optional)
- If `FASTPATH_IF_CUSTOM` and there is at least one `custom` candidate → return only `[custom + phrase_dict]` (up to 10), cache for 20s.

7) Merge, dedupe, and rank
- Merge in the following order: `custom`, `phrase_dict`, `phrase`, `next`, `prefix`, `neighbor`, `embedding`.
- Dedupe by `full` (preferred) or `token|type`.
- Score normalization and weighting:
  - Normalizer: if `SCORE_NORMALIZER = 'log1p'` → `log1p(max(0, rawScore))`, else passthrough
  - Weight by type from `WEIGHTS` (defaults: custom 2.0, phrase_dict 1.35, phrase 1.1, next 1.0, prefix 0.9, neighbor 0.75, embedding 1.05)
  - `finalScore = normalized * weight`
- Pin up to 2 `custom` items, then fill with top-scored others to a max of 10.

8) Response and caching
- Set `x-suggest-latency-ms`, cache 20s under cache key, return payload.

## Configuration (suggest.config.ts)

- Toggles: `ENABLE_PREFIX`, `ENABLE_NEIGHBOR`, `ENABLE_NEXT`, `ENABLE_PHRASE`, `ENABLE_PHRASE_DICT`, `EMBEDDINGS.ENABLED`
- Limits: `LIMITS.PREFIX`, `LIMITS.NEIGHBOR`, `LIMITS.PHRASE_DICT`, `LIMITS.NEXT`
- Phrase expansion: `PHRASE_FIRST_LIMIT`, `PHRASE_SECOND_LIMIT`, `MAX_PHRASE_TOKENS`
- Behavior: `DISABLE_NEIGHBOR_ON_SPACE` (default true), `FASTPATH_IF_CUSTOM`
- Scoring: `SCORE_NORMALIZER` ('log1p' | 'none'), `WEIGHTS` per type
- Data sources for build: `SOURCE_FIELDS` (default ["title", "name"]) plus `STOPWORDS`, `SYNONYMS`

## Maintenance and Related Endpoints

### POST /api/search/rebuild_keyword_vectors

Builds co-occurrence vectors, next-token transitions, and mined phrases from product data.

1) Source & tokenization
- Read products with `published_on != null`, projecting `SOURCE_FIELDS` (default: title, name).
- Concatenate fields, segment tokens via `SegmentService.tokens`.
- Keep a display sample (with diacritics) for each normalized token.

2) Statistics
- `tokenFreq`: documents per token (use Set(tokens) per doc)
- `pairFreq`: document-level co-occurrence for token pairs
- `nextCounts`: sequential counts `prev -> next`
- `next2Counts`: two-step context counts `p1|||p2 -> next`
- `totalDocs`: total products scanned

3) Neighbors (PPMI)
- PMI(a,b) = `log( (cooc * totalDocs) / (fa * fb) )`
- PPMI = `max(0, PMI)`
- For each token with `freq >= minFreq` (default 3), keep top `maxNeighbors` (default 10), include `display`, `freq`, `neighbors`.
- Upsert to `keywordVectorRepo`.

4) Next-token (1-step, 2-step)
- For each `prev` (or `ctx = p1|||p2`), compute `score = count / total` and keep top ~12.
- Upsert to `keywordNextRepo`.

5) Phrase mining
- Seed bigrams from top co-occurring nexts per `prev`.
- `pushPhrase(tokens, count)` filters by `MIN_PHRASE_COUNT` (default 3) and PMI ≥ `MIN_PHRASE_PMI` (default 2.0) using the first pair in tokens.
- Expand to up to `PHRASE_MAX_NGRAM` (default 3) using nextCounts; branch limits keep the search bounded.
- Upsert to `keywordPhraseRepo` as `{ phrase, tokens[], count, pmi }`.

6) Result
- Returns `{ tokens: <#docs> }`. Parameters: `{ minFreq = 3, maxNeighbors = 10 }`.

### POST /api/search/rebuild_dictionary

Builds a spell dictionary to support typo suggestions.

1) Extract tokens via Mongo aggregation
- Project `title`, `alias`, `brand.text`, `vendor`, `tags` from products
- Reduce to a single text string; split by spaces; unwind tokens; drop empty; group and count

2) Normalize and merge frequencies
- `normalizeBasic` per token → term
- Merge counts by normalized term, keep a single `original` sample with diacritics

3) Bulk upsert into `spell_dictionary`
- Entry: `{ term, original, freq }`
- Utility methods:
  - `isKnownToken(term)`, `getByTerm(term)`, `topCandidatesForToken(token, limit)`

4) Usage in typo suggest
- Levenshtein-based ranking (distance threshold depends on token length)
- Prefer lower distance and higher frequency
- Beautify final suggestion by mapping normalized terms back to `original` with diacritics

## Analytics and Online Learning

- POST `/api/search/suggest_click`: record user selection `{ q, chosen, token, type }`
- GET `/api/search/suggest_stats`: view counts per suggestion type
- Online learning hooks
  - After successful search: `onlineLearnerService.learnFromQuery(query)`
  - After suggest click: `onlineLearnerService.learnFromClick(q, token|chosen)`

## Edge Cases and Notes

- Empty query → returns empty data (cached)
- `DISABLE_NEIGHBOR_ON_SPACE = true` → neighbor suggestions are suppressed immediately after a space
- Self-loop avoidance: `next` suggestions filter out `token === prev`
- Display vs token: display keeps diacritics; token is normalized

## Example Requests (optional)

- GET `/api/search/suggest_keywords?query=tai%20ng`
- GET `/api/search/typo_suggest?query=tai%20ngeh`
- POST `/api/search/rebuild_keyword_vectors`
- POST `/api/search/rebuild_dictionary`

---

For implementation references, see:
- `src/controllers/search.controller.ts` (main logic)
- `src/services/keyword_vector_builder.service.ts` (build pipeline)
- `src/services/spell_suggest.service.ts` and `src/repositories/search/spell_dictionary.repository.ts` (typo)
- `src/repositories/search/*` (keyword_vector, keyword_next, keyword_phrase, custom_phrase)
- `src/config/suggest.config.ts` (tuning)
  </script>

  <script src="https://cdn.jsdelivr.net/npm/marked/marked.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/highlight.js@11.9.0/lib/common.min.js"></script>
  <script>
    // Configure marked for heading IDs (for TOC if needed) and code highlight
    marked.setOptions({
      highlight: function(code, lang){
        try { return window.hljs.highlight(code, {language: lang}).value; }
        catch(e){ try { return window.hljs.highlightAuto(code).value; } catch{ return code; } }
      },
      breaks: false
    });

    function slugify(str){
      return str.toLowerCase()
        .replace(/[^a-z0-9\u00C0-\u024f\s-]/g,'')
        .trim().replace(/\s+/g,'-').replace(/-+/g,'-');
    }

    function buildTOC(root){
      const headings = root.querySelectorAll('h1, h2, h3');
      if(!headings.length) return;
      const toc = document.getElementById('tocRoot');
      toc.innerHTML = '<strong>Mục lục</strong>';
      const ul = document.createElement('ul');
      ul.style.listStyle='none';
      ul.style.padding='0';
      let lastH1, lastH2;
      headings.forEach(h => {
        if(!h.id){
          h.id = slugify(h.textContent);
        }
        // Anchor copy link
        if(!h.querySelector('.anchor-link')){
          const a = document.createElement('a');
          a.href = '#' + h.id;
          a.className = 'anchor-link';
          a.textContent = '#';
          h.appendChild(a);
        }
        const li = document.createElement('li');
        const a = document.createElement('a');
        a.textContent = h.textContent.replace(/#/g,'').trim();
        a.href = '#' + h.id;
        const level = h.tagName === 'H1' ? 1 : h.tagName === 'H2' ? 2 : 3;
        a.style.paddingLeft = (level - 1) * 14 + 'px';
        li.appendChild(a);
        ul.appendChild(li);
      });
      toc.appendChild(ul);
      toc.style.display='block';
    }

    function pickFile(){
      const params = new URLSearchParams(location.search);
      const f = (params.get('file')||'full').toLowerCase();
      switch(f){
        case 'overview': return { md: 'README_suggest_keywords_overview.md', label: 'Overview'};
        case 'summary': return { md: 'README_suggest_keywords_summary.md', label: 'Summary'};
        case 'user': return { md: 'README_suggest_keywords_user.md', label: 'User'};
        case 'legacy': return { md: 'README-suggest.md', label: 'Legacy'};
        case 'full':
        default: return { md: 'README_suggest_keywords_full.md', label: 'Full'};
      }
    }

    async function loadMarkdown(){
      const el = document.getElementById('doc');
      const status = document.getElementById('renderStatus');
      const choice = pickFile();
      const dl = document.getElementById('downloadMd');
      if(dl){ dl.href = './' + choice.md; dl.download = choice.md; dl.textContent = 'Tải ' + choice.label + ' (.md)'; }
      let md = null;
      let usedFallback = false;
      try{
        const res = await fetch('./'+choice.md,{cache:'no-store'});
        if(!res.ok) throw new Error('HTTP '+res.status);
        md = await res.text();
        status.textContent = 'fetched';
      }catch(err){
        const inline = document.getElementById('readme-inline');
        if(inline){
          md = inline.textContent;
          usedFallback = true;
          status.textContent = 'fallback inline';
        } else {
          el.innerHTML = '<p style="color:#b91c1c">Không tải được README: '+String(err)+'</p>';
          status.textContent = 'error';
          return;
        }
      }
      const html = marked.parse(md);
      if(usedFallback){
        const note = document.createElement('div');
        note.className='muted';
        note.style.marginBottom='10px';
        note.textContent='Đang hiển thị bản README nhúng sẵn (fetch bị chặn / offline).';
        el.innerHTML='';
        el.appendChild(note);
      }
      const container = document.createElement('div');
      container.innerHTML = html;
      el.appendChild(container);
      el.dataset.loaded = 'true';
      if(window.hljs) window.hljs.highlightAll();
      buildTOC(el);
    }
  loadMarkdown();

    // Layout toggle (side TOC)
    document.getElementById('toggleLayout').addEventListener('click', () => {
      document.body.classList.toggle('with-toc');
    });
    document.getElementById('printBtn').addEventListener('click', () => window.print());

    // If highlight theme fails to load (network), mark pre blocks with a subtle border already handled by base CSS.
    const hlLink = document.getElementById('hljs-theme');
    hlLink.addEventListener('error', () => {
      console.warn('Highlight theme failed to load; using fallback styles');
    });
  </script>
</body>
</html>
